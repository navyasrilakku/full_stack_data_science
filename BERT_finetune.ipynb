{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLvICYk2ff9Y"
   },
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kt253PFmVN2r",
    "outputId": "be2c942e-f225-49f2-88d1-197f26cf8c84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "     -------------------------------------- 10.1/10.1 MB 519.5 kB/s eta 0:00:00\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "     ------------------------------------ 480.6/480.6 kB 391.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: torch in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (1.12.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (1.5.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 969.8 kB/s eta 0:00:00\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.5.1-cp38-abi3-win_amd64.whl (303 kB)\n",
      "     -------------------------------------- 303.7/303.7 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.24.0\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "     ------------------------------------ 450.7/450.7 kB 612.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     --------------------------------------- 64.9/64.9 kB 14.5 kB/s eta 0:00:00\n",
      "Collecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "     ------------------------------------ 133.4/133.4 kB 328.3 kB/s eta 0:00:00\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-18.1.0-cp39-cp39-win_amd64.whl (25.3 MB)\n",
      "     -------------------------------------- 25.3/25.3 MB 795.4 kB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.11.11-cp39-cp39-win_amd64.whl (442 kB)\n",
      "     -------------------------------------- 442.2/442.2 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     -------------------------------------- 78.5/78.5 kB 726.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.1-cp39-cp39-win_amd64.whl (44 kB)\n",
      "     -------------------------------------- 45.0/45.0 kB 445.3 kB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl (51 kB)\n",
      "     -------------------------------------- 51.8/51.8 kB 266.2 kB/s eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.18.3-cp39-cp39-win_amd64.whl (90 kB)\n",
      "     -------------------------------------- 91.0/91.0 kB 395.7 kB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "     ------------------------------------ 116.3/116.3 kB 377.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, tqdm, safetensors, requests, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.1\n",
      "    Uninstalling huggingface-hub-0.20.1:\n",
      "      Successfully uninstalled huggingface-hub-0.20.1\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.2.0 dill-0.3.8 frozenlist-1.5.0 huggingface-hub-0.27.1 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 pyarrow-18.1.0 requests-2.32.3 safetensors-0.5.1 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.47.1 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\My world\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "    WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\My world\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\My world\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\My world\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.20 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\my world\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wANmUDRlV-Tv"
   },
   "source": [
    "**BertForSequenceClassification** is a model provided by the Hugging Face Transformers library. It is a fine-tuned variant of BERT (Bidirectional Encoder Representations from Transformers) designed specifically for sequence classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ct5Uf6LWXbEX"
   },
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jdIkIgspWGYf",
    "outputId": "7db2dfc9-3948-4e91-bb50-8a9fd860b88b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1114,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1114,\n        \"samples\": [\n          \"Largely forgettable tale in which mercenary Kerman & employer Agren travel into the jungle in search of Agren's missing sister.<br /><br />Despite its connection to the cannibal movie family, this film is more of an extreme version of Rene Cardona's \\\"Guyana - Crime of the Century\\\". Lenzi clearly aims to exploit the (at that time) topical Jonestown massacre, by depicting a rogue, self righteous zealot with a penchant for bigamy and just a hint of megalomania (played with ruthless intensity by Ivan Rassimov) leading his motley crew flock into self inflicted oblivion. With sister in toe, Kerman & Agren attempt to stop the rot, but after several failed coups, they end up fleeing into the \\\"Green Inferno\\\", only to run afoul the locals and their notorious appetites.<br /><br />One in a string of excessive gore fests that emerged in the late seventies/early eighties, where every new addition seemed to engage in a one-upmanship contest with its predecessor, by attempting to contrive the most gory and graphic display ever brought to motion pictures. This inferior instalment employs all the motifs and gimmicks of the others, but with much less success.<br /><br />Was it the so called \\\"Amazonian natives\\\" who looked like they were Bollywood rejects (this film was made on location in Sri Lanka), or the inept \\\"decapitation\\\" and \\\"castration\\\" scenes that seriously diminished the authenticity that was apparent in \\\"Cannibal Holocaust\\\"? You can decide. Without spoiling the conclusion, it appeared as though Lenzi put more emphasis in his shock and awe climax than in the basic requirement for a cohesive ending, where all loose ends are resolved. Most unsatisfying.<br /><br />As with the others, where the extent of the graphic depictions of violence toward humans is limited (thankfully), the filmmakers have spared no extreme in inflicting the worst possible cruelty on hapless animals in their pursuit of the most sadistic shocks. Unfortunately, the only thing shocking about this film is that it rates a mention among others of the ilk, that deal with the subject matter more convincingly.<br /><br />If there are any redeemable features at all, Kerman is an affable if somewhat one-dimensional leading man, and his bevy of scantily clad co-stars (Agren, Lai and Senatore) provide some visual respite from the relentless slayings.\",\n          \"Okay, last night, August 18th, 2004, I had the distinct displeasure of meeting Mr. Van Bebble at a showing of the film The Manson Family at the Three Penny in Chicago as part of the Chicago Underground Film Festival. Here's what I have to say about it. First of all, the film is an obvious rip off of every Kenneth Anger, Roman Polanski, Oliver Stone and Terry Gilliam movie I've ever seen. Second of all, in a short Q & A session after the show Mr. Van Bebble immediately stated that he never made any contact with the actual Manson Family members or Charlie himself, calling them liars and saying he wanted nothing to do with them, that the film was based on his (Van Bebble's) take on the trial having seen it all from his living room on TV and in the news (and I'm assuming from the Autobiography and the book Helter Skelter which were directly mimicked through the narrative). So I had second dibs on questions, I asked if he was trying to present the outsider, Mtv, sex drugs and rock 'n roll version and not necessarily the true story. This question obviously pissed off the by now sloshed director who started shouting \\\"f*** you, shut the f*** up, this is the truth! All those other movies are bullsh**!\\\"<br /><br />Well anyway, I didn't even think about how ridiculous this was until the next day when I read the tagline for the film, \\\"You've heard the laws side of the story...now hear the story as it is told by the Manson Family.\\\" Excuse me, if this guy has never even spoken to the family and considers them to be liars that he doesn't want to have anything to do with, how in God's name can he tell the story for them!? This is the most ridiculous statement I have ever heard! The film was obviously catered to the sex drugs and rock 'n roll audience that it had no trouble in attracting to the small, dimly lit theatre, and was even more obviously spawned by the sex drugs and rock 'n roll mind of a man who couldn't even watch his own film without getting up every ten minutes to go get more beer or to shout some sort of Rocky Horroresque call line to the actors on screen. This film accomplishes little more than warping the public's image of actual events (which helped shape the state of America and much of the world today) into some sort of Slasher/Comic Book/Porno/Rape fantasy dreamed up by an obviously shallow individual.<br /><br />The film was definitely very impressive to look at. The soundtrack was refreshing as it contained actual samples of Charlie's work with the Family off of his Lie album. The editing was nice and choppy to simulate the nauseating uncertainty of most modern music videos. All in all this film would have made a much better addition to the catalogues at Mtv than to the Underground Film Festival or for that matter the minds of any intellectual observers. I felt like I was at a midnight Rocky Horror viewing the way the audience was dressed and behaving (probably the best part of the experience). The cast was very good with the exception of Charlie who resembled some sort of stoned Dungeons and Dragons enthusiast more than the actual role he was portraying. The descriptions the film gave of him as full of energy, throwing ten things at you and being very physical about it all the while did not match at all the slow, lethargic, and chubby representation that was actually presented.<br /><br />All in all the film basically explains itself as Sadie (or maybe it was Linda) declares at the end, \\\"You can write a bunch of bullsh** books or make a bunch of bullsh** movies...etc. etc.\\\" Case in point. Even the disclaimer \\\"Based on a True Story\\\" is a dead giveaway, signalling that somewhere beneath this psychedelic garbage heap lay the foundation of an actual story with content that will make and has made a difference in the world. All you have to do is a little bit of alchemy to separate the truth from the the crap, or actually, maybe you could just avoid it all together and go read a book instead.<br /><br />All I can say is this, when the film ended I got a free beer so I'm glad I went, but not so glad I spent fifteen dollars on my ticket to be told to shut the f*** up for asking the director a question. Peace.\",\n          \"I saw this movie a fews years ago and was literally swept away by it. So charming and so very romantic. David Duchovny and Ms. Driver have chemistry that is so hot, you will need to take off a layer of clothing. The supporting cast is 100% top notch. Just watching Caroll O'Connor and Robert Loggia play off one another is pure poetry. Bonnie Hunt and Jim Bellushi and a wonderful team and some of the films most charming moments are when they are on the screen. Like Jim Belushi screaming at his children to go to sleep \\\"FOREVER!\\\" or him dancing in the kitchen. This film made we wish I knew people like that in my own life. Not to mention, what woman does not want David Duchovny for a boyfriend?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-cd1ab821-e154-4eb3-b095-b04060904b4d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd1ab821-e154-4eb3-b095-b04060904b4d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cd1ab821-e154-4eb3-b095-b04060904b4d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cd1ab821-e154-4eb3-b095-b04060904b4d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ed5cd40b-ae62-469e-a83f-805a40c772f4\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed5cd40b-ae62-469e-a83f-805a40c772f4')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ed5cd40b-ae62-469e-a83f-805a40c772f4 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel('/content/IMDB Dataset_sample.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxgJfsIpYB1O"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Convert sentiment to numerical labels\n",
    "data['sentiment'] = data['sentiment'].map({\"positive\": 1, \"negative\": 0})\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gl4nIAt5Ya_x",
    "outputId": "d83fa0ad-eef9-445a-83f1-2cae3c0149a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['review', 'sentiment', '__index_level_0__'],\n",
       "    num_rows: 891\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOOk4qkgYo3l",
    "outputId": "930a9faa-5eb7-452a-d528-2ba7f0e2f0ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': ['This film was pretty good. I am not too big a fan of baseball, but this is a movie that was made to help understand the meaning of love, determination, heart, etc.<br /><br />Danny Glover, Joseph Gordon-Levitt, Brenda Fricker, Christopher Lloyd, Tony Danza, and Milton Davis Jr. are brought in with a variety of talented actors and understanding of the sport. The plot was believable, and I love the message. William Dear and the guys put together a great movie.<br /><br />Most sports films revolve around true stories or events, and they often do not work well. But this film hits a 10 on the perfectness scale, even though there were a few minor mistakes here and there.<br /><br />10/10',\n",
       "  'How do you take a cast of experienced, well-known actors, and put together such a stupid movie? Nimrod Antel has the answer: Armored. Six co-workers at an armored car business decide to steal a large shipment of cash themselves. But, just as they get to first base with their plans, everything unravels quickly. With a plot like this, you\\'d think it couldn\\'t be too bad, at least for an action movie. However, in the first 40 minutes or more of this movie we see what appear to be 6 normal, everyday kind of guys. They joke, they laugh, have a few drinks together, etc. Then, we suddenly learn they\\'re planning to rob their own business. The hero Ty, (Columbus Short), is sucked into the scheme because of the cold, cruel world, even though he\\'s a decorated veteran, nice guy, and reliable employee. Oh my, oh my! Then in the last 40 minutes of the film, these former regular guys nearly all turn into money-crazed psychos, willing to butcher each other for cash. In the last scenes Mike, (Matt Dillon), goes on a suicidal rampage for no other reason than to kill his former friend. The viewer has no hint before this ending that these men are this ruthless and bloodthirsty. It\\'s utterly unbelievable and \"B movie\" is almost too kind for this sort of cheesy plot. I would say don\\'t waste your time--too bad no one gave Laurence Fishburne, Jean Reno or Fred Ward the same advice before making this picture.',\n",
       "  \"If you like me is going to see this in a film history class or something like that at your school, try to convince your teacher to see something else. believe me, anything is better than this movie. it is slow paced, confusing, boring, poorly constructed, gory, gringy, do I need to go on? It's message is good, but I have seen them been handled better in several other films. The acting isn't even any good. This movie is just even more awkward, as it start off as being funny (not intensional though)because of it's surreal story, than at the end, just becomes uncomfortable to watch.<br /><br />I honestly feel like 1 hour and 40 minutes of my life has been robbed. Why would anyone want to watch a girls describe a threesome for 10 minutes, than watch them drive through a traffic jam for 20 minutes, listen to a hippie who can make sheep appear, witness a sort of rape, than see the female lead role eat her husband.<br /><br />Honestly this movie deserves nothing but a 1/10. And if your not happy with my preview,seriously I'm an open minded guy and I like movies that protest through symbolism, but this movie was just awful. make any excuse you can, to avoid this film.\",\n",
       "  'This film is an abomination of all that is worthy in film making. The lead actor surprises his audience by not actually acting at all. We have to watch almost two hours of his bland soulless face. The jokes are all lame I never laughed once it was Saturday night there were 5 of us having a beer all up for a laugh and then we put this on and you could feel all the warmth and colour being drained from the room. The film ended and the mood was ruined so we all went our separate ways, ruined the night ! OK so pros and cons. Pros beautiful setting in Hawaii, looks good on bluray. Cons worst acting ever; you can tell everyone concerned is just thinking about payday. Predictable poor plot. Zero character development. Forced jokes which fall flat. Many shots of the guys penis which to be fair acts better than him and has more charisma. May all makers of this film hang their heads in shame and hold their flaccid manhoods cheap.',\n",
       "  \"I would recommend this film to anyone who is searching for a relaxing, fun-filled, thought-provoking movie. The absence of sex, vulgarities and violence made for a most pleasant evening. I especially enjoyed the Buffalo scene, but that's probably because I live a short distance from there. Even so, this film could have been produced in any city; it's the theme that's so important here. I'm just grateful that Manna From Heaven dropped down on us. Try it...you'll like it!\"],\n",
       " 'sentiment': [1, 0, 0, 0, 1],\n",
       " '__index_level_0__': [381, 327, 998, 959, 582]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4HJ2vPiYytS"
   },
   "source": [
    "# Tokenize the Text\n",
    "\n",
    "Use the BERT tokenizer to preprocess the text.\n",
    "\n",
    "\n",
    "\n",
    "The batched=True parameter in the map method of Hugging Face Dataset means that the mapping function (in this case, tokenize_function) will process the data in batches (groups of examples) rather than processing one example at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5POn1SxZTLL"
   },
   "source": [
    "1. padding=\"max_length\"\n",
    "\n",
    "**Purpose:** Ensures that all tokenized sequences have the same length.\n",
    "\n",
    "**How It Works:**\n",
    "If a sequence is shorter than max_length, it will be padded with a special padding token (e.g., [PAD]) until it reaches max_length.\n",
    "\n",
    "If a sequence is longer than max_length, it won't be padded further.\n",
    "\n",
    "**Why Itâ€™s Important:**\n",
    "Models like BERT require inputs of uniform length for batch processing.\n",
    "This ensures that all sequences in a batch can be processed simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hm54rOoZlDs"
   },
   "source": [
    "**2. truncation=True**\n",
    "\n",
    "**Purpose:** Ensures that sequences longer than max_length are truncated to fit within the limit.\n",
    "\n",
    "**How It Works:**\n",
    "If a sequence exceeds the max_length, it will be truncated by removing tokens from the end of the sequence.\n",
    "\n",
    "**Why Itâ€™s Important:**\n",
    "Prevents exceeding the model's maximum input size, which could cause errors or inefficiency.\n",
    "Useful for handling datasets with highly variable text lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_KruSpcZxMu"
   },
   "source": [
    "**3. max_length=128**\n",
    "\n",
    "**Purpose:** Sets the desired length for input sequences.\n",
    "\n",
    "**How It Works:**\n",
    "Determines the fixed size for all tokenized sequences after padding/truncation.\n",
    "\n",
    "**Why Itâ€™s Important:**\n",
    "Most pre-trained models have a maximum token limit (e.g., 512 for BERT).\n",
    "Reducing max_length to 128 saves computation time and memory, especially if most sequences are shorter than 128 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "44692d6cc5614b8fbaea9a00adbafa5a",
      "14e9ca16cb334a9995359d719eb52a09",
      "5877294793bf4a0a9443a42d33af1172",
      "283bbdf6fd8a4288b8a516ce482d90ac",
      "001272cb61404e5b85d5f942de4aa48b",
      "06e6ca47767c4c8f990524ed82cb8620",
      "62e404117ed94676b9d85e80a699e1c7",
      "37cd4955abb54dfb8b1236f857cd2960",
      "0828a5f286dd4ff68e408b066fede42b",
      "88cbdc3728624fdcb683bbb375ebf26e",
      "8adee060de1d45c2860fd982fd449337",
      "c1671ae5c2eb47aaaf65aec7f6b67784",
      "0cba6f59746540789d97bb80deb29ab5",
      "79620007b3f64ebf8b8f7f80f45bdbbd",
      "37ccf035f4664ee39134378616c4000f",
      "33916e5a26fc4694a0302d297eecd7d6",
      "4326d67b92454ce4bbcb7920089b6001",
      "c374cb311d3e4caebdfceb4570172d60",
      "ec4b26372f264cb88584054925b23948",
      "4f49335b699c473180247ea887a9c25d",
      "01c6e9a9e7634f60a7dea12c30f896c9",
      "dff0859242c44eabb1882e20426b39c8"
     ]
    },
    "id": "7optuCRyXSq9",
    "outputId": "f25f8e56-13f9-4b36-8df1-db1b50e07a47"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44692d6cc5614b8fbaea9a00adbafa5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/891 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1671ae5c2eb47aaaf65aec7f6b67784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"review\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "train_dataset = train_dataset.remove_columns([\"review\", \"__index_level_0__\"])\n",
    "test_dataset = test_dataset.remove_columns([\"review\", \"__index_level_0__\"])\n",
    "\n",
    "# Rename the sentiment column to labels\n",
    "train_dataset = train_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "\n",
    "# Set the format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3uiwcI8aFug"
   },
   "source": [
    "# Initialize the Model\n",
    "\n",
    "Load the BertForSequenceClassification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8GtySxlZ6s4",
    "outputId": "499caebb-b280-4cee-90a7-73342b58e06a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2  # Binary classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVI-hVZBaap1"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtWrYcY8biXI"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XtPsiJDcJpQ"
   },
   "source": [
    "https://wandb.ai/omkar-nallagoni-naresh-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbt55KSecoQb",
    "outputId": "32fc1619-6d78-4d9f-8486-4bf061313ca8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=epoch,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=./logs,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=10,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3,\n",
       "optim=adamw_torch,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=./results,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard', 'wandb'],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=./results,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=1000,\n",
       "save_strategy=steps,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=1000\n",
    ")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBMv0fghaPK2",
    "outputId": "5d87c7a7-99d6-4bc3-ced5-79fdab9bdc14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7e927c3cde10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "hrrM4VS4c3X6",
    "outputId": "e9d054ea-d0e2-42fe-ca41-d6fe6f2bcf43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 01:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.344800</td>\n",
       "      <td>0.386422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.449739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.418112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=336, training_loss=0.3559872868603894, metrics={'train_runtime': 89.6145, 'train_samples_per_second': 29.828, 'train_steps_per_second': 3.749, 'total_flos': 175823962744320.0, 'train_loss': 0.3559872868603894, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "Qfp6ry76eqtk",
    "outputId": "4ec36969-fe96-4c72-d9da-5663a66aa031"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4181116819381714, 'eval_runtime': 1.6963, 'eval_samples_per_second': 131.465, 'eval_steps_per_second': 16.507, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Szuzy-9e0VK",
    "outputId": "4d42f2c7-4f63-4191-e9a0-9beecbad2833"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment_model/tokenizer_config.json',\n",
       " './sentiment_model/special_tokens_map.json',\n",
       " './sentiment_model/vocab.txt',\n",
       " './sentiment_model/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./sentiment_model\")\n",
    "tokenizer.save_pretrained(\"./sentiment_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTgy4HdXfKii"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"./sentiment_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./sentiment_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXhSHlo-fNfb"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(review, model, tokenizer):\n",
    "    # Tokenize the input review\n",
    "    inputs = tokenizer(\n",
    "        review,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    # Move tensors to the same device as the model (CPU or GPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Map predictions to sentiment labels\n",
    "    sentiment = \"positive\" if predictions.item() == 1 else \"negative\"\n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbldhgf5fR1n",
    "outputId": "c2bc2790-45b2-4162-9013-0bc5de950a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I really loved this movie. The story was good!\n",
      "Predicted Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "review = \"I really loved this movie. The story was good!\"\n",
    "sentiment = predict_sentiment(review, model, tokenizer)\n",
    "print(f\"Review: {review}\")\n",
    "print(f\"Predicted Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-JsbVb2ac2d"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJrwtemfcrNP"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0n_VErHcuNV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001272cb61404e5b85d5f942de4aa48b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01c6e9a9e7634f60a7dea12c30f896c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06e6ca47767c4c8f990524ed82cb8620": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0828a5f286dd4ff68e408b066fede42b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0cba6f59746540789d97bb80deb29ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4326d67b92454ce4bbcb7920089b6001",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c374cb311d3e4caebdfceb4570172d60",
      "value": "Map:â€‡100%"
     }
    },
    "14e9ca16cb334a9995359d719eb52a09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06e6ca47767c4c8f990524ed82cb8620",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_62e404117ed94676b9d85e80a699e1c7",
      "value": "Map:â€‡100%"
     }
    },
    "283bbdf6fd8a4288b8a516ce482d90ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88cbdc3728624fdcb683bbb375ebf26e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8adee060de1d45c2860fd982fd449337",
      "value": "â€‡891/891â€‡[00:06&lt;00:00,â€‡147.42â€‡examples/s]"
     }
    },
    "33916e5a26fc4694a0302d297eecd7d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37ccf035f4664ee39134378616c4000f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01c6e9a9e7634f60a7dea12c30f896c9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_dff0859242c44eabb1882e20426b39c8",
      "value": "â€‡223/223â€‡[00:01&lt;00:00,â€‡182.99â€‡examples/s]"
     }
    },
    "37cd4955abb54dfb8b1236f857cd2960": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4326d67b92454ce4bbcb7920089b6001": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44692d6cc5614b8fbaea9a00adbafa5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14e9ca16cb334a9995359d719eb52a09",
       "IPY_MODEL_5877294793bf4a0a9443a42d33af1172",
       "IPY_MODEL_283bbdf6fd8a4288b8a516ce482d90ac"
      ],
      "layout": "IPY_MODEL_001272cb61404e5b85d5f942de4aa48b"
     }
    },
    "4f49335b699c473180247ea887a9c25d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5877294793bf4a0a9443a42d33af1172": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37cd4955abb54dfb8b1236f857cd2960",
      "max": 891,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0828a5f286dd4ff68e408b066fede42b",
      "value": 891
     }
    },
    "62e404117ed94676b9d85e80a699e1c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79620007b3f64ebf8b8f7f80f45bdbbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec4b26372f264cb88584054925b23948",
      "max": 223,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f49335b699c473180247ea887a9c25d",
      "value": 223
     }
    },
    "88cbdc3728624fdcb683bbb375ebf26e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8adee060de1d45c2860fd982fd449337": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1671ae5c2eb47aaaf65aec7f6b67784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0cba6f59746540789d97bb80deb29ab5",
       "IPY_MODEL_79620007b3f64ebf8b8f7f80f45bdbbd",
       "IPY_MODEL_37ccf035f4664ee39134378616c4000f"
      ],
      "layout": "IPY_MODEL_33916e5a26fc4694a0302d297eecd7d6"
     }
    },
    "c374cb311d3e4caebdfceb4570172d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dff0859242c44eabb1882e20426b39c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec4b26372f264cb88584054925b23948": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
