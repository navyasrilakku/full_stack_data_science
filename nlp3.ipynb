{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b0701d",
   "metadata": {},
   "source": [
    "**general word embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbded6",
   "metadata": {},
   "source": [
    "- 1 bag of words and TF-IDF\n",
    "- 2 Latent Semantic Analysis(LSA)\n",
    "- 3 word2Vec developed by google\n",
    "- 4 GloVe developed by standford university\n",
    "- 5 FastText developed by FaceBook\n",
    "- 6 Contextual Embeddings\n",
    "     - ELMo: ELMo(embeddings from language models): developed by allen institute for AI\n",
    "     - BERT(Bidirectional encoder representations from transformers): developed by Hugging Face now takeover by google\n",
    "     - T5(Text-to-text transfer transformer): developed by google, T5 treats all NLP tasks as text-to-text problems, unifying multiple tasks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb474ac",
   "metadata": {},
   "source": [
    "**example**\n",
    "- review1: game of thrones is an amazing tv series!\n",
    "- review2: game of thrones is the best tv series!\n",
    "- review3: game of thrones is so great"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d25065",
   "metadata": {},
   "source": [
    "**vocabulary - dictionary of words**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed55f3b",
   "metadata": {},
   "source": [
    "- each row corresponds to a different review, while the rows are the unique words, contained in the three\n",
    "\n",
    "**sentence-1**\n",
    "- sky is nice\n",
    "\n",
    "**sentence-2**\n",
    "- clouds are nice\n",
    "\n",
    "**sentence-3**\n",
    "- sky is nice and clouds are nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1671cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sentences=['sky is nice','clouds are nice','sky is nice and clouds are nice']\n",
    "cleaned_sentences=[]\n",
    "for sentence in sentences:\n",
    "    word=sentence.lower()\n",
    "    word=word.split()\n",
    "    word=[i  for i in word if i not in set(stopwords.words('english'))]\n",
    "    word=\" \".join(word)\n",
    "    cleaned_sentences.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f35388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sky nice', 'clouds nice', 'sky nice clouds nice']\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abe3ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 2, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(max_features=3)\n",
    "BagOfWords=cv.fit_transform(cleaned_sentences)\n",
    "BagOfWords\n",
    "BagOfWords.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2a0059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BagOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0fb651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_request_for_signature',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_validate_data',\n",
       " '_validate_ngram_range',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'preprocessor',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_transform_request',\n",
       " 'stop_words',\n",
       " 'strip_accents',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a656d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=['game of thrones is an amazing tv series!', 'game of thrones is the best tv series!',\n",
    "'game of thrones is so great']\n",
    "cleaned_sentence=[]\n",
    "for sentence in l1:\n",
    "    word=sentence.lower()\n",
    "    word=word.split()\n",
    "    word=[i  for i in word if i not in set(stopwords.words('english'))]\n",
    "    word=\" \".join(word)\n",
    "    cleaned_sentence.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5d5ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv1=CountVectorizer(max_features=3)\n",
    "BagOfWords=cv1.fit_transform(cleaned_sentence)\n",
    "BagOfWords\n",
    "BagOfWords.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c577fd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'game': np.int64(0), 'thrones': np.int64(2), 'series': np.int64(1)}\n"
     ]
    }
   ],
   "source": [
    "print(cv1.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab3e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
